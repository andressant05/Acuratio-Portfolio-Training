Máquina Virtual andres_vllm con LLaMA 3B (Entrenamiento del modelo)
Instrucciones:

Inicia una nueva máquina virtual (VM) y ponla en funcionamiento.

Abre el terminal SSH.

Edita la configuración de nginx:

sudo nano /etc/nginx/sites-available/vllm  # CAMBIA LA IP
sudo systemctl restart nginx
docker restart my_vllm_container

Inicia Jupyter Lab dentro de la VM:
sudo env "PATH=$PATH" jupyter lab --allow-root --port=8888

En tu máquina local, crea un túnel SSH para acceder a Jupyter:
gcloud compute ssh andres-vllm-2 --zone=europe-west1-b -- -L 8888:localhost:8888
Accede a: http://localhost:8888

Para descargar y ejecutar LLaMA 3B:
docker run -d --runtime nvidia --gpus all \
  --name my_vllm_container \
  -v ~/.cache/huggingface:/root/.cache/huggingface \
  --env "HUGGING_FACE_HUB_TOKEN=***REMOVED***" \
  -p 8000:8000 --ipc=host \
  vllm/vllm-openai:latest \
  --model meta-llama/Llama-3.2-3B-Instruct \
  --max-model-len 100000
