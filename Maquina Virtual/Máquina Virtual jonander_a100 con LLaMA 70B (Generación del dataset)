Máquina Virtual jonander_a100 con LLaMA 70B (Generación del dataset)
Instrucciones:

Inicia la máquina virtual (VM).
Abre el terminal SSH.

Configura nginx:
sudo nano /etc/nginx/sites-available/vllm  # CAMBIA LA IP
sudo systemctl restart nginx
docker restart my_vllm_container
docker logs my_vllm_container -f  # (verifica logs)

Inicia Jupyter Lab:
sudo env "PATH=$PATH" jupyter lab --allow-root --port=9999

Crea el túnel SSH desde tu máquina local:
gcloud compute ssh jonander-a100 --zone=us-central1-a -- -L 9999:localhost:9999
Abre: http://localhost:9999/lab

Para descargar y correr el modelo LLaMA 70B:
docker run -d --runtime nvidia --gpus all \
  --name my_vllm_container \
  -v /home/jonanderjimenezz/.cache/huggingface/:/root/.cache/huggingface \
  -p 9000:8000 --ipc=host \
  --env "HUGGING_FACE_HUB_TOKEN=***REMOVED***" \
  vllm/vllm-openai:latest \
  --model meta-llama/Llama-3.3-70B-Instruct \
  --tensor-parallel-size 4
